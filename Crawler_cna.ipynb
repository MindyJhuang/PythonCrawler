{
 "metadata": {
  "name": "",
  "signature": "sha256:52d962a4224c58ce53e4920633d6a879b357cd5ed32549e71c1eb1b6f33c7695"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urlparse, requests, os, re, time\n",
      "from bs4 import BeautifulSoup\n",
      "from pymongo import Connection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catalog_dic = {'/list/aall-1.aspx':'','http://cnavideo.cna.com.tw':'','/newsphotolist/aspt-1.aspx':''}    # \u6392\u9664\u4e0d\u53d6\u7684\u65b0\u805e\u985e\u5225\n",
      "link_pool_dic = {}    # \u66ab\u5b58\u9023\u7d50\u6e05\u55ae\u88e1\u7684\u9023\u7d50\n",
      "new_link_dic = {}    # \u66ab\u5b58\u6e05\u55ae\u9023\u7d50\u88e1\u9762\u6c92\u6709\u7684\u65b0\u9023\u7d50\n",
      "retry_dic = {}    # \u66ab\u5b58\u9023\u7d50\u5931\u6557\u7684\u9023\u7d50\n",
      "doc_id_dic = {}    # \u66ab\u5b58 mongoDB \u4e2d\u5df2\u5b58\u5728\u7684 document id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u53d6\u4e2d\u592e\u793e\u7684\u65b0\u805e\u5206\u985e\u9023\u7d50\n",
      "def get_catalog_link (homepage):\n",
      "    result = requests.get(homepage)\n",
      "    response = result.text.encode('utf8')\n",
      "    soup = BeautifulSoup(response)\n",
      "    catalog_link = soup.select('.sf-menu li')    # \u53d6\u5305\u8457\u65b0\u805e\u985e\u5225\u7684\u9023\u7d50\u5217\n",
      "    for num in catalog_link:\n",
      "        if num.find('span') is not None:    # \u53bb\u6389\u975e\u65b0\u805e\u985e\u5225\u7684\u5176\u4ed6\u5167\u5bb9 (\u6b64\u6307\u65b0\u805e\u985e\u5225\u9023\u7d50\u6240\u5c55\u958b\u7684\u65b0\u805e\u524d\u4e94\u7b46\u6e05\u55ae)\n",
      "            catalog = num.find('a')['href']     # \u53d6\u51fa\u65b0\u805e\u985e\u5225\u6a19\u7c64\u7684\u65b0\u805e\u985e\u5225\u9023\u7d50\n",
      "            if catalog not in catalog_dic:    # \u53ea\u8981\u65b0\u805e\u985e\u5225\u4e0d\u5728\u9ed1\u540d\u55ae(catalog_dic)\u4e2d\u5c31\u9023\u7d50\u5230\u8a72\u65b0\u805e\u985e\u5225\u7684\u8868\u5217\u6e05\u55ae\u9801\u9762\n",
      "                url = urlparse.urljoin('http://www.cna.com.tw',catalog.split('1')[0])\n",
      "                get_news_link(url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u53d6\u65b0\u805e\u9023\u7d50\u5217\u8868\n",
      "def get_news_link (url):\n",
      "    get_url = url+'%d.aspx'    # \u5c07\u8868\u5217\u6e05\u55ae\u7684\u9023\u7d50\u8a2d\u6210\u52d5\u614b\u9023\u7d50\n",
      "    fomate = \"%s_list.txt\"    # \u5c07\u5132\u5b58\u65b0\u805e\u9023\u7d50\u6e05\u55ae\u7684\u6a94\u540d\u8a2d\u6210\u52d5\u614b\n",
      "    file_name = fomate%get_url.split('list/')[1].split('-')[0]    # \u6a94\u540d\u6703\u96a8\u8457\u65b0\u805e\u985e\u5225\u6539\u8b8a\n",
      "    for page in range (1,5):    # \u81ea\u52d5\u7ffb\u9801\n",
      "        news_url = get_url%page    # \u8868\u5217\u6e05\u55ae\u7684 %d \u6703\u96a8\u8457 page \u6539\u8b8a, \u85c9\u6b64\u9023\u7d50\u5230\u8868\u5217\u6e05\u55ae\u7684\u4e0d\u540c\u9801\u6578, range \u53ef\u81ea\u8a02\n",
      "        result = requests.get(news_url)\n",
      "        response = result.text.encode('utf8')\n",
      "        soup = BeautifulSoup(response)\n",
      "        link_list = soup.find('div',{'class':'block block_p7'}).findAll('a')    # \u53d6\u51fa\u8868\u5217\u6e05\u55ae\u4e0b\u6240\u6709\u7684\u9023\u7d50\u6a19\u7c64\n",
      "        if len(link_list) > 0:    # \u5224\u65b7\u8a72\u9801\u9762\u662f\u5426\u6709\u53d6\u5230\u9023\u7d50\n",
      "            for links in link_list:\n",
      "                news_link = urlparse.urljoin('http://www.cna.com.tw',links['href'])    # \u53d6\u9023\u7d50\u6a19\u7c64\u4e0b\u7684\u9023\u7d50\n",
      "                check_link(news_link, file_name)\n",
      "                #print news_link    # check \u9023\u7d50\u662f\u5426\u6709\u53d6\u6210\u529f\n",
      "        else:\n",
      "            break\n",
      "    f = open(\"cna/\"+file_name, 'w')       \n",
      "    for overwrite_link in new_link_dic: # \u5c07 new_link_dic \u4e2d\u7684\u9023\u7d50\u8986\u5beb\u5230\u5c0d\u61c9\u7684\u65b0\u805e\u985e\u5225\u6a94\u6848\u4e2d\n",
      "        f.write(overwrite_link + \"\\n\")\n",
      "    f.close()        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u78ba\u8a8d\u9023\u7d50\u662f\u5426\u91cd\u8907\n",
      "def check_link (news_link, file_name):\n",
      "    dirs = os.listdir('cna/')    # \u5b58\u653e\u9023\u7d50\u6e05\u55ae\u6a94\u6848\u7684\u76ee\u9304, \u900f\u904e os \u65b9\u6cd5\u8b80\u53d6\u8a72\u76ee\u9304\u4e0b\u7684\u6240\u6709\u6a94\u540d(\u542b\u76ee\u9304\u8207\u6a94\u6848)\n",
      "    if file_name not in dirs:    # \u5224\u65b7\u76ee\u9304\u4e0b\u6709\u6c92\u6709\u8a72\u6a94\u6848\n",
      "        f = open(\"cna/\"+file_name, 'w') \n",
      "        f.write(news_link + \"\\n\")\n",
      "        f.close()\n",
      "    else:\n",
      "        f = open(\"cna/\"+file_name, 'r')\n",
      "        for line in f.readlines(): \n",
      "            link_pool_dic[line]=1    # \u8b80\u53d6\u9023\u7d50\u6e05\u55ae\u4e2d\u7684\u6240\u6709\u9023\u7d50, \u4e26\u5b58\u5165 link_pool_dic \u88e1\n",
      "        f.close()\n",
      "        if news_link not in link_pool_dic:     # \u5224\u65b7\u65b0\u53d6\u7684\u9023\u7d50\u662f\u5426\u6709\u5728 link_pool_dic \u4e2d, \u6c92\u6709\u7684\u8a71\u653e\u5165 new_link_dic\n",
      "            new_link_dic[news_link] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u91cd\u53d6\u9023\u7d50\n",
      "def retry_get_info():\n",
      "    for retry_link in retry_dic:    # \u91cd\u9023 retry_dic \u4e2d\u7684\u6240\u6709\u9023\u7d50\n",
      "        result = requests.get(retry_link)\n",
      "        response = result.text.encode('utf8')\n",
      "        soup = BeautifulSoup(response)\n",
      "        title = soup.find('h2').text\n",
      "\n",
      "        filename = retry_link.split('news/')[1].split('/')[0]+'_list.txt'    # \u53d6\u6a19\u982d\n",
      "        time_clean = soup.find('div',{'class':'date'}).contents[0].replace('\\n','').replace('\\r','').replace('        ','')    # \u6e05\u7406\u65e5\u671f\u6a19\u7c64\u4e0b\u7684\u683c\u5f0f\n",
      "        date = time_clean.encode('utf8').split('\uff1a')[1]    # \u53d6\u65e5\u671f\n",
      "        content = soup.find('div',{'class':'box_2'}).text.replace('\\n','')[:-7]    # \u53d6\u5167\u6587\n",
      "        data_insert(title, date, content, retry_link, filename)\n",
      "        time.sleep(5)    # \u958b\u5b8c\u4e00\u500b\u5167\u6587\u9023\u7d50\u7761\u4e94\u79d2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u53d6\u65b0\u805e\u5167\u5bb9\n",
      "def get_news_contents (path):\n",
      "    dirs = os.listdir(path)\n",
      "    for filename in dirs:\n",
      "        f = open(path+filename,'r')\n",
      "        for line in f.readlines(): \n",
      "            try:\n",
      "                news_link = line.strip()\n",
      "                result = requests.get(news_link)\n",
      "                response = result.text.encode('utf8')\n",
      "                soup = BeautifulSoup(response)\n",
      "                title = soup.find('h2').text\n",
      "                time_clean = soup.find('div',{'class':'date'}).contents[0].replace('\\n','').replace('\\r','').replace('        ','')\n",
      "                date = time_clean.encode('utf8').split('\uff1a')[1]\n",
      "                content = soup.find('div',{'class':'box_2'}).text.replace('\\n','')[:-7]\n",
      "                data_insert(title, date, content, news_link, filename)\n",
      "                time.sleep(5)\n",
      "                print '.'\n",
      "            except:\n",
      "                retry_dic[news_link]=1    # \u5c07\u5167\u6587\u9023\u7d50\u5931\u6557\u7684\u9023\u7d50\u4e1f\u5165 retry_dic \u4e2d\n",
      "                #print news_link    # check \u5931\u6557\u7684\u9023\u7d50\n",
      "        f.close()\n",
      "        retry_get_info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u5b58\u5165mongoDB\n",
      "def data_insert (title, date, content, news_link, filename):\n",
      "    con = Connection()    # \u958b\u555f\u672c\u6a5f mongoDB \u9023\u7dda, \u9060\u7aef\u9023\u7dda\u8acb\u7528\n",
      "    db = con.news    # \u9023\u5230 mongoDB \u5e95\u4e0b\u7684 news db\n",
      "    cna_news = db.cna    # \u9023\u5230 mongoDB \u5e95\u4e0b\u7684 cna collection\n",
      "       # \u4e0a\u8ff0\u4e09\u884c\u53ef\u6539\u5beb\u6210 a = Connection().news.cna        \n",
      "    doc_catalog = filename.split('_')[0]\n",
      "    doc_id = news_link.split(doc_catalog+'/')[1].split('-')[0]\n",
      "    \n",
      "    for a in cna_news.find():    # \u5c07 mongoDB \u4e2d\u7684 news_id \u5b58\u5165 doc_id_dic\n",
      "        doc_id_dic[a.values()[6]] = 1\n",
      "\n",
      "    if doc_id not in doc_id_dic:    # \u5224\u65b7\u8a72 news \u7684 id \u662f\u5426\u5728 doc_id_dic \u4e2d\n",
      "        data = {\"_id\":doc_id,\n",
      "                    \"title\":title,\n",
      "                   \"date\":date,\n",
      "                   \"catalog\":doc_catalog,\n",
      "                   \"from\":\"\u4e2d\u592e\u793e\",\n",
      "                   \"news_link\":news_link,\n",
      "                   \"content\":content}\n",
      "        cna_news.insert(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get_catalog_link('http://www.cna.com.tw/')\n",
      "#get_news_contents('cna/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.cna.com.tw/news/afe/201409130121-1.aspx\n",
        "http://www.cna.com.tw/news/aopl/201409130283-1.aspx"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}